{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b3NHRB2wbipr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.autograd as Variable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnwaUvkifqUy",
    "outputId": "797b4b8e-9515-4c57-bfc1-8b0da62866bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FeZqr3cbipt"
   },
   "source": [
    "## **1. Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5RsHoPjobipv"
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "src_sents = [\"i love you\", \"how are you\", \"good night\", \"thank you\", \"i am fine\"]\n",
    "tgt_sents = [\"tôi yêu bạn\", \"bạn khỏe không\", \"chúc ngủ ngon\", \"cảm ơn bạn\", \"tôi khỏe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rno6PevUbipw"
   },
   "source": [
    "**Create vocabulaies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PCzckosrbipw"
   },
   "outputs": [],
   "source": [
    "src_words = set()\n",
    "trg_words = set()\n",
    "\n",
    "for sent in src_sents:\n",
    "    src_words.update(sent.split()) # update function allows us to add many items in the same thing\n",
    "\n",
    "for sent in tgt_sents:\n",
    "    trg_words.update(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTYjnCzkbipx",
    "outputId": "a56468f6-503a-4eb6-9624-7655849f6151"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am', 'are', 'fine', 'good', 'how', 'i', 'love', 'night', 'thank', 'you'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBKP2Mokbipx",
    "outputId": "1262fb25-8ba0-4753-b9fa-196ca71a50bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bạn', 'chúc', 'cảm', 'không', 'khỏe', 'ngon', 'ngủ', 'tôi', 'yêu', 'ơn'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Puq_CpIQbipy"
   },
   "source": [
    "Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cveNRswbipz",
    "outputId": "18d9352e-7229-4f22-ac2e-9c4d229b17b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<sos>': 0,\n",
       " '<eos>': 1,\n",
       " '<pad>': 2,\n",
       " '<unk>': 3,\n",
       " 'fine': 4,\n",
       " 'are': 5,\n",
       " 'night': 6,\n",
       " 'good': 7,\n",
       " 'am': 8,\n",
       " 'you': 9,\n",
       " 'i': 10,\n",
       " 'how': 11,\n",
       " 'love': 12,\n",
       " 'thank': 13}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = {\"<sos>\":0, \"<eos>\": 1, \"<pad>\":2, \"<unk>\":3}\n",
    "\n",
    "for i, word in enumerate(src_words, start= 4):\n",
    "    src_vocab[word] = i\n",
    "src_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Km4yD4Vzbip1",
    "outputId": "ca137ca7-d30f-420b-af73-38f39082d7a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<sos>': 0,\n",
       " '<eos>': 1,\n",
       " '<pad>': 2,\n",
       " '<unk>': 3,\n",
       " 'bạn': 4,\n",
       " 'tôi': 5,\n",
       " 'ơn': 6,\n",
       " 'yêu': 7,\n",
       " 'cảm': 8,\n",
       " 'ngủ': 9,\n",
       " 'chúc': 10,\n",
       " 'không': 11,\n",
       " 'ngon': 12,\n",
       " 'khỏe': 13}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_vocab = {\"<sos>\":0, \"<eos>\": 1, \"<pad>\":2, \"<unk>\": 3}\n",
    "for i, word in enumerate(trg_words, start = 4):\n",
    "    trg_vocab[word] = i\n",
    "trg_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PsO7zdwmbip2"
   },
   "outputs": [],
   "source": [
    "def create_dictionary(src_sents, trg_sents):\n",
    "    src_words = set()\n",
    "    trg_words = set()\n",
    "\n",
    "    # create vocab\n",
    "    for sent in src_sents:\n",
    "        src_words.update(sent.split()) # update function allows us to add many items in the same thing\n",
    "\n",
    "    for sent in trg_sents:\n",
    "        trg_words.update(sent.split())\n",
    "\n",
    "    #\n",
    "    src_vocab = {\"<sos>\":0, \"<eos>\": 1, \"<pad>\":2, \"<unk>\":3}\n",
    "    for i, word in enumerate(src_words, start= 4):\n",
    "        src_vocab[word] = i\n",
    "\n",
    "\n",
    "    trg_vocab = {\"<sos>\":0, \"<eos>\": 1, \"<pad>\":2, \"<unk>\": 3}\n",
    "    for i, word in enumerate(trg_words, start = 4):\n",
    "        trg_vocab[word] = i\n",
    "\n",
    "    return  src_vocab, trg_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HGgqWQambip2"
   },
   "outputs": [],
   "source": [
    "class Read_Dataset(Dataset):\n",
    "    def __init__(self, src_sents, tgt_sents, src_vocab, trg_vocab, max_leng = 50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.src = src_sents\n",
    "        self.tgt = tgt_sents\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.max_leng = max_leng\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        src_sentence = self.src[index]\n",
    "        trg_sentence = self.tgt[index]\n",
    "\n",
    "        # tokenization\n",
    "        src_indides = [self.src_vocab['<sos>']] + [self.src_vocab.get(word.lower(), self.src_vocab['<unk>']) for word in src_sentence.split()]  + [self. src_vocab['<eos>']]\n",
    "        trg_indides = [self.trg_vocab['<sos>']] + [self.trg_vocab.get(word.lower(), self.trg_vocab['<unk>']) for word in trg_sentence.split()]  + [self.trg_vocab['<eos>']]\n",
    "\n",
    "        # padding\n",
    "        src_indides = src_indides[:self.max_leng] + [self.src_vocab['<pad>']] * (self.max_leng - len(src_indides))\n",
    "        trg_indides = trg_indides[:self.max_leng] + [self.trg_vocab['<pad>']] * (self.max_leng - len(trg_indides))\n",
    "\n",
    "        return torch.LongTensor(src_indides), torch.LongTensor(trg_indides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uojcnzm-bip3",
    "outputId": "e25afd1e-b19c-4594-b2e4-81bfd63c7de0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 12,  9,  1]), tensor([0, 5, 7, 4, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Read_Dataset(src_sents, tgt_sents, src_vocab, trg_vocab, 5)\n",
    "\n",
    "data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "n5_TSCw3bip3"
   },
   "outputs": [],
   "source": [
    "traindata = DataLoader(data, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA84qVY_bip4"
   },
   "source": [
    "## 2. **Build Transformers From Scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMxh_yusbip4"
   },
   "source": [
    "**Embedding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Hm4z3_Gobip4"
   },
   "outputs": [],
   "source": [
    "class Embedding_layer(nn.Module):\n",
    "    def __init__(self, vocab_len, d_model = 512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = d_model\n",
    "        self.emb = nn.Embedding(vocab_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x) * math.sqrt(self.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9f1w_3Fbip4",
    "outputId": "2e9bdd88-0010-4982-b8fd-f3ffc5f8f45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1440,  2.1720,  0.1891],\n",
       "        [-0.4419, -2.4272,  0.6007],\n",
       "        [ 0.1082, -0.5154, -0.8250],\n",
       "        [ 1.9928,  0.1610, -0.3965],\n",
       "        [-0.8749,  1.8202,  1.1426]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = Embedding_layer(len(src_vocab), d_model= 3)\n",
    "s,t  = data.__getitem__(0)\n",
    "em(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FInp1kicbip5"
   },
   "source": [
    "**Possition layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5teC1Xcbip5"
   },
   "source": [
    "$a^x = e^{x*ln(a)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaOpIXKHbip5"
   },
   "source": [
    "$ w_k = 10000^{\\frac{2*k}{d}} =  e  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0-opOArbip5"
   },
   "source": [
    "$ w_k = 10000^{\\frac{2*k}{d}} =  e ^ {\\frac{2*k}{d} * ln(10000)}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rb0YOmXxbip5"
   },
   "outputs": [],
   "source": [
    "class Possition_layer(nn.Module):\n",
    "    def __init__(self, max_leng = 200, d_model = 512, dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.ones(max_leng, d_model)\n",
    "        possition = torch.arange(0, max_leng, dtype=float).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:,::2] = torch.sin(possition * div_term)\n",
    "        pe[:,1::2] = torch.cos(possition * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0) # add bach_size dimention\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "\n",
    "    def forward(self, x): # x embedded\n",
    "        x = x + self.pe[:,:x.size(1),:]  # chièu 1 là batchsize\n",
    "\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwCgWKkJbip6",
    "outputId": "bc13aa98-6885-41f0-bd11-704e0ba7a6d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.9813,  0.7836,  2.0076, -1.9121],\n",
       "         [ 2.8081,  0.0000,  2.7557, -0.0000],\n",
       "         [ 0.5863, -1.9362,  0.4612, -1.3980],\n",
       "         [ 0.3048,  0.5989,  0.6166,  0.0000],\n",
       "         [ 0.0000,  0.1610, -1.4853,  3.6390]],\n",
       "\n",
       "        [[-2.9813,  0.7836,  2.0076, -1.9121],\n",
       "         [ 0.9150,  0.0000, -0.3539, -0.6157],\n",
       "         [ 0.0000,  1.9236,  1.9641,  0.3816],\n",
       "         [ 0.0000,  0.5989,  0.6166,  2.2479],\n",
       "         [ 0.3136,  0.1610, -1.4853,  3.6390]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = iter(traindata)\n",
    "d,y = next(x)\n",
    "em = Embedding_layer(len(src_vocab), d_model= 4)\n",
    "e = em(d)\n",
    "p = Possition_layer(40, 4, 0.1)\n",
    "x = em(d)\n",
    "p(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wIDTotbbip6"
   },
   "source": [
    "**Self Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "E77zPCC4bip6"
   },
   "outputs": [],
   "source": [
    "def attention(q,k,v, mask = None, dropout = None):\n",
    "\n",
    "    # q,k,v shape [batch_size, seq_leng, d_model]\n",
    "    d_model = q.size(-1)\n",
    "    score = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_model)\n",
    "\n",
    "    if mask is not None:\n",
    "        score = score.masked_fill(mask ==0, 1e-10)\n",
    "\n",
    "    sort_max = F.softmax(score, -1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        sort_max = dropout(sort_max)\n",
    "\n",
    "    return torch.matmul(sort_max,v), sort_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ziq3OK7pbip6"
   },
   "source": [
    "**Multihead Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qrz9uFLjbip7"
   },
   "outputs": [],
   "source": [
    "class Multihead_attention(nn.Module):\n",
    "    def __init__(self, head = 8, d_model = 256, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % head == 0\n",
    "        self.head = head\n",
    "        self.d_k = d_model // head # chia d_model thành nhiều đầu\n",
    "\n",
    "        self.q_weight = nn.Linear(d_model, d_model)\n",
    "        self.k_weight = nn.Linear(d_model, d_model)\n",
    "        self.v_weight = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q,k,v,mask = None):\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # -1 represents sequence length\n",
    "        q = self.q_weight(q).view(batch_size, -1,self.head, self.d_k).transpose(1,2) # đổi thành ma trận các head ma trận\n",
    "        k = self.k_weight(k).view(batch_size, -1,self.head, self.d_k).transpose(1,2) # đổi thành ma trận các head ma trận\n",
    "        v = self.v_weight(v).view(batch_size, -1,self.head, self.d_k).transpose(1,2) # đổi thành ma trận các head ma trận\n",
    "\n",
    "        if mask is not None:\n",
    "            # mask: [batch_size, 1, 1, seq_len] -> [batch_size, h, seq_len, seq_len]\n",
    "            mask = mask.unsqueeze(1)  # Add head dimension\n",
    "            # This ensures it can be broadcasted over attention scores\n",
    "\n",
    "        score, attn = attention(q,k,v,mask, self.dropout)\n",
    "\n",
    "        concat = score.transpose(1,2).contiguous().view(batch_size, -1, self.head * self.d_k)\n",
    "\n",
    "        return self.out(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVIgK9NAbip8"
   },
   "source": [
    "**Norm Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wid80X12bip8"
   },
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.ones(d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a * (x - mean) / (std + self.eps) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parrzCJ2bip8"
   },
   "source": [
    "**FeedWord Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fwaZBAzwbip9"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\" Trong kiến trúc của chúng ta có tầng linear\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDME5rUKbip9"
   },
   "source": [
    "**Encoder layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pYGDLWd4bip9"
   },
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, head = 8, d_model = 512, dropout = 0.1 ):\n",
    "        super().__init__()\n",
    "        self.attn = Multihead_attention(head , d_model,dropout)\n",
    "\n",
    "        self.norm1 = Norm(d_model)\n",
    "        self.norm2 = Norm(d_model)\n",
    "\n",
    "        self.ffn = FeedForward(d_model,dropout=dropout)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x, mask):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.attn(x2, x2, x2, mask))\n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ffn(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52RGBQmtbip9"
   },
   "source": [
    "**Decoder Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TawUzL2hbip-"
   },
   "outputs": [],
   "source": [
    "class Decoder_Layer(nn.Module):\n",
    "    def __init__(self,head , d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 norm layers\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "\n",
    "        # 3 dropout layers\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "\n",
    "        # 2 multi-head attention blocks\n",
    "        self.attn_1 = Multihead_attention(head, d_model, dropout=dropout)\n",
    "        self.attn_2 = Multihead_attention(head, d_model, dropout=dropout)\n",
    "\n",
    "        # Feedforward network\n",
    "        self.ffn = FeedForward(d_model, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, encoder_output, encoder_output, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ffn(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdg0SwEJbip-"
   },
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nBRg_BdSbip-"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_len = 100000, d_model = 521, N = 8,head = 8, dropout = 0.1 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = Embedding_layer(vocab_len,d_model)\n",
    "        self.ps = Possition_layer(200,  d_model,  dropout)\n",
    "        self.encoder_layers = get_clones(Encoder_layer(head=head, d_model=d_model, dropout=dropout), N)\n",
    "\n",
    "        self.n = N\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self,x, mask):\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x = self.ps(x)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            x = self.encoder_layers[i](x, mask)\n",
    "\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SJ-Rt8cbip-"
   },
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZqAmAY-lbiqB"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_len = 10000, d_model = 256, N = 8,head = 8, dropout = 0.1 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = Embedding_layer(vocab_len,d_model)\n",
    "        self.ps = Possition_layer(200,  d_model,  dropout)\n",
    "        self.decoder_layers = get_clones(Decoder_Layer(head, d_model, dropout), N)\n",
    "        self.n = N\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self,encoder_output,x, src_mask, trg_mask):\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x = self.ps(x)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            x = self.decoder_layers[i](x, encoder_output, src_mask, trg_mask)\n",
    "\n",
    "\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCZndc2cbiqB"
   },
   "source": [
    "**Tranformer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iyXqVDvdbiqB"
   },
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        # Correct the order of arguments for the decoder\n",
    "        d_output = self.decoder(e_outputs, trg, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "t46x6bCec8hy"
   },
   "outputs": [],
   "source": [
    "# Mask functions\n",
    "def nopeak_mask(size, device):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    # Remove the Variable() call\n",
    "    np_mask = (torch.from_numpy(np_mask) == 0).to(device)\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg, src_pad, trg_pad, device):\n",
    "    src_mask = (src != src_pad).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != trg_pad).unsqueeze(-2)\n",
    "        size = trg.size(1)\n",
    "        np_mask = nopeak_mask(size, device)\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else:\n",
    "        trg_mask = None\n",
    "\n",
    "    return src_mask, trg_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSKZGymebiqB"
   },
   "source": [
    "**Model Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "e2sRkSJ7hhq6"
   },
   "outputs": [],
   "source": [
    "# path = \"data/translation_dataset.csv\"\n",
    "path = \"/content/drive/MyDrive/Dataset_of_Colab/translation_dataset.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "src_vocab, trg_vocab = create_dictionary(df[\"English\"].values, df[\"Vietnamese\"].values)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Read_Dataset(train_df[\"English\"].values, train_df[\"Vietnamese\"].values, src_vocab, trg_vocab, max_leng=200)\n",
    "val_dataset = Read_Dataset(val_df[\"English\"].values, val_df[\"Vietnamese\"].values, src_vocab, trg_vocab, max_leng=200)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nyr9fGel5It",
    "outputId": "e712efdc-f55d-40f9-96d1-7dcf1e1b7da4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "K2TeZM4IbiqC"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(\n",
    "    len(src_vocab),\n",
    "    len(trg_vocab),\n",
    "    256,\n",
    "    4,\n",
    "    8,\n",
    "    0.1,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001,  betas=(0.9, 0.98))\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = trg_vocab[\"<pad>\"]) # trg_vocab[\"<pad>\"] equals 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EecP0I-TbiqC"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader,optimizer, criterion, device, num_epochs=10, batch_size=32):\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for src_batch, tgt_batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            src_batch, tgt_batch = src_batch.long().to(device), tgt_batch.long().to(device)\n",
    "\n",
    "            print(src_batch.dtype, tgt_batch.dtype)\n",
    "\n",
    "\n",
    "            trg_input = tgt_batch[:, :-1]\n",
    "            trg_output = tgt_batch[:, 1:]\n",
    "\n",
    "            src_mask, trg_mask = create_masks(src_batch, trg_input, 2, 2 , device)\n",
    "\n",
    "            output = model(src_batch, trg_input, src_mask, trg_mask)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg_output = trg_output.contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, trg_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src_batch, tgt_batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}\"):\n",
    "                src_batch, tgt_batch = src_batch.long().to(device), tgt_batch.long().to(device)\n",
    "\n",
    "                trg_input = tgt_batch[:, :-1]\n",
    "                trg_output = tgt_batch[:, 1:]\n",
    "\n",
    "                src_mask, trg_mask = create_masks(src_batch, trg_input, 2, 2 , device)\n",
    "\n",
    "                output = model(src_batch, trg_input, src_mask, trg_mask)\n",
    "\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output.contiguous().view(-1, output_dim)\n",
    "                trg_output = trg_output.contiguous().view(-1)\n",
    "\n",
    "                loss = criterion(output, trg_output)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"best_transformer_model.pt\")\n",
    "            print(\"Saved best model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "0bc8ddffd2cf46eca6e07836295910bb",
      "17fbb27c32874c5bb039976367f2dc9a",
      "b64cf7cbc3ce45e193f2cf728318e087",
      "1df985825bcb46c08000770d537adb7d",
      "14993dd2cd384ca3b821edad5c544267",
      "2083a3bfe1f94939985427167b97d768",
      "9dc6d83aba364240bee95facb6d19463",
      "ec245a8b4d764bf3b65d7bca81d658c0",
      "2028c789b9724545956f080c55f6f31b",
      "7976368d713d4537b3193ea5774f1c03",
      "c1ef699627534f32ae65970998ce2271"
     ]
    },
    "id": "QA6F58VpbiqC",
    "outputId": "2fe90137-a586-4ca9-d7a9-29e5b0aeaaf4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc8ddffd2cf46eca6e07836295910bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/3537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bc8ddffd2cf46eca6e07836295910bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17fbb27c32874c5bb039976367f2dc9a",
       "IPY_MODEL_b64cf7cbc3ce45e193f2cf728318e087",
       "IPY_MODEL_1df985825bcb46c08000770d537adb7d"
      ],
      "layout": "IPY_MODEL_14993dd2cd384ca3b821edad5c544267"
     }
    },
    "14993dd2cd384ca3b821edad5c544267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17fbb27c32874c5bb039976367f2dc9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2083a3bfe1f94939985427167b97d768",
      "placeholder": "​",
      "style": "IPY_MODEL_9dc6d83aba364240bee95facb6d19463",
      "value": "Training Epoch 1:   0%"
     }
    },
    "1df985825bcb46c08000770d537adb7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7976368d713d4537b3193ea5774f1c03",
      "placeholder": "​",
      "style": "IPY_MODEL_c1ef699627534f32ae65970998ce2271",
      "value": " 0/3537 [00:00&lt;?, ?it/s]"
     }
    },
    "2028c789b9724545956f080c55f6f31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2083a3bfe1f94939985427167b97d768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7976368d713d4537b3193ea5774f1c03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dc6d83aba364240bee95facb6d19463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b64cf7cbc3ce45e193f2cf728318e087": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec245a8b4d764bf3b65d7bca81d658c0",
      "max": 3537,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2028c789b9724545956f080c55f6f31b",
      "value": 0
     }
    },
    "c1ef699627534f32ae65970998ce2271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec245a8b4d764bf3b65d7bca81d658c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
